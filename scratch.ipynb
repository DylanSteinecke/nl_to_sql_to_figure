{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "4de3e3f1",
   "metadata": {},
   "source": [
    "### Main"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7203696f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---Example Document---\n",
      "Table: albums\n",
      "Primary key: AlbumId\n",
      "Columns:\n",
      " - AlbumId (INTEGER) [PRIMARY KEY NOT NULL] (ex: 1, 4, 2)\n",
      " - Title (NVARCHAR(160)) [NOT NULL] (ex: For Those About To Rock We Salute You, Balls to the Wall, Restless and Wild)\n",
      " - ArtistId (INTEGER) [NOT NULL] (ex: 1, 2, 3)\n",
      "Foreign key(s):\n",
      " - albums.ArtistId → artists.ArtistId\n",
      "\n",
      "86 documents in vector database\n",
      "3 relevant documents found for \"Who are the top 3 artists?\"\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Fetching 1 files: 100%|██████████| 1/1 [00:00<?, ?it/s]\n",
      "Fetching 1 files: 100%|██████████| 1/1 [00:00<?, ?it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generating SQL...\n",
      " SELECT a.Name FROM artists a ORDER BY a.Name ASC NULLS LAST LIMIT 3\n"
     ]
    }
   ],
   "source": [
    "import logging\n",
    "import sys\n",
    "\n",
    "from ctransformers import AutoModelForCausalLM\n",
    "import sqlite3\n",
    "\n",
    "from generate_schema_documents import make_schema_documents\n",
    "from embed_documents_into_vector_db import upsert_schema_docs_to_lancedb, \\\n",
    "    get_relevant_documents \n",
    "from create_sql_query import check_sql_schema_and_syntax, generate_sql_cpu, docs_to_context_string, \\\n",
    "    extract_table_descriptions, check_forbidden_keywords, \\\n",
    "    check_sql_schema_and_syntax\n",
    "\n",
    "def set_up_logger(log_file: str, log_level: int):\n",
    "    '''\n",
    "    Set up the logger for this utility.\n",
    "\n",
    "    :param log_file: Full path to the file used to store logs\n",
    "    :param log_level: Level used for logging\n",
    "    '''\n",
    "    log_handlers = []\n",
    "\n",
    "    # Create the stderr handler\n",
    "    stderr_handler = logging.StreamHandler(stream=sys.stderr)\n",
    "    stderr_handler.setLevel(logging.WARNING)\n",
    "    stderr_formatter = logging.Formatter('%(levelname)s: %(message)s')\n",
    "    stderr_handler.setFormatter(stderr_formatter)\n",
    "    log_handlers.append(stderr_handler)\n",
    "\n",
    "    # Create the stdout handler \n",
    "    if log_level <= logging.INFO:\n",
    "        stdout_handler = logging.StreamHandler(stream=sys.stdout)\n",
    "        stdout_handler.setLevel(log_level)\n",
    "        stdout_formatter = logging.Formatter('%(message)s')\n",
    "        stdout_handler.setFormatter(stdout_formatter)\n",
    "        stdout_handler.addFilter(lambda record: record.levelno <= logging.INFO)\n",
    "        log_handlers.append(stdout_handler)\n",
    "\n",
    "    # Create the file handler\n",
    "    file_handler = logging.FileHandler(log_file, mode='a')\n",
    "    file_handler.setLevel(log_level)\n",
    "    file_formatter = logging.Formatter('%(asctime)s %(message)s')\n",
    "    file_handler.setFormatter(file_formatter)\n",
    "    log_handlers.append(file_handler)\n",
    "\n",
    "    # Set logging handlers and level for root logger\n",
    "    logging.basicConfig(\n",
    "        handlers=log_handlers, level=log_level, datefmt='%I:%M:%S %p')\n",
    "\n",
    "    logging.getLogger('numba').setLevel(logging.WARNING)\n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    query = \"What is the first song by the first artist?\"\n",
    "    query = \"Who are the top 3 artists?\"\n",
    "\n",
    "    ### Set up logging --------------------------------------------------------\n",
    "    set_up_logger(log_file=\"app.log\", log_level=logging.DEBUG)\n",
    "\n",
    "    ### Connect to the database ------------------------------------------------\n",
    "    db_path = \"data/chinook.db\"\n",
    "    conn = sqlite3.connect(db_path)\n",
    "\n",
    "\n",
    "    ### Take SQL tables and columns, then generate \"documents\" for each -------\n",
    "    # NOTE: Later add LLM-generated descriptions for each table/column\n",
    "    # NOTE: Use structured json format for documents\n",
    "    documents = make_schema_documents(conn)\n",
    "    logging.debug(f'---Example Document---\\n{documents[0].text}\\n')\n",
    "\n",
    "\n",
    "    ### Embed documents in a vector database NOTE: max(<thresh, 5) ------------\n",
    "    vector_db = upsert_schema_docs_to_lancedb(\n",
    "                    db_dir=\"chinook_schema_docs\",\n",
    "                    documents=documents)\n",
    "    logging.debug(f'{vector_db.count_rows()} documents in vector database')\n",
    "\n",
    "\n",
    "    ### Validate document relevance -----------------------------------------\n",
    "    # NOTE: Re-rank the top documents\n",
    "    \n",
    "\n",
    "    ### Retrieve relevant columns from vector database ----------------------\n",
    "    sql_context_df = get_relevant_documents(vector_db, query)\n",
    "    logging.debug(f'{len(sql_context_df)} relevant documents found for {query}')\n",
    "    table_descriptions = extract_table_descriptions(sql_context_df, documents)\n",
    "    sql_context = docs_to_context_string(sql_context_df)\n",
    "    sql_context += f'\\n{table_descriptions}'\n",
    "    \n",
    "\n",
    "    ### Generate SQL query --------------------------------------------------\n",
    "    model = AutoModelForCausalLM.from_pretrained(\n",
    "        'MaziyarPanahi/sqlcoder-7b-2-GGUF',\n",
    "        model_file='sqlcoder-7b-2.Q4_K_M.gguf', \n",
    "        model_type='mistral', \n",
    "        context_length=4096, # NOTE: check context length\n",
    "        gpu_layers=0)\n",
    "    valid_sql_query = False\n",
    "    attempts = 0\n",
    "    MAX_ATTEMPTS = 5\n",
    "    while not valid_sql_query and attempts < MAX_ATTEMPTS:\n",
    "        attempts += 1\n",
    "        sql_query = generate_sql_cpu(\n",
    "            retrieved_docs=sql_context, \n",
    "            question=query, \n",
    "            model=model)\n",
    "        print(f'Generated: {sql_query}')\n",
    "\n",
    "        ### Validate SQL query ----------------------------------------\n",
    "        # Check for forbidden keywords\n",
    "        has_forbidden, error_msg = check_forbidden_keywords(sql_query)\n",
    "        if has_forbidden:\n",
    "            print(f'{error_msg}')\n",
    "            continue\n",
    "        \n",
    "        # Check SQL syntax and schema existence\n",
    "        is_valid_sql, error_msg = check_sql_schema_and_syntax(conn, sql_query)\n",
    "        if not is_valid_sql:\n",
    "            logging.error(f'SQL syntax or schema error: {error_msg}')\n",
    "            continue\n",
    "        else:\n",
    "            logging.debug('SQL query passed the validation steps.')\n",
    "            valid_sql_query = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "88796111",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1f6e0e46",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a9b2ff37",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'c:\\\\Users\\\\dsteinec\\\\Documents\\\\Jupyter_Notebooks\\\\nl_to_data'"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os\n",
    "\n",
    "os.getcwd()\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4bc2e474",
   "metadata": {},
   "source": [
    "### SQL Database"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "e9b9399f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(              name\n",
       " 0           albums\n",
       " 1          artists\n",
       " 2        customers\n",
       " 3        employees\n",
       " 4           genres\n",
       " 5    invoice_items\n",
       " 6         invoices\n",
       " 7      media_types\n",
       " 8   playlist_track\n",
       " 9        playlists\n",
       " 10          tracks,\n",
       "    table_name   column_name      data_type  primary_key\n",
       " 0      albums       AlbumId        INTEGER            1\n",
       " 1      albums         Title  NVARCHAR(160)            0\n",
       " 2      albums      ArtistId        INTEGER            0\n",
       " 3     artists      ArtistId        INTEGER            1\n",
       " 4     artists          Name  NVARCHAR(120)            0\n",
       " ..        ...           ...            ...          ...\n",
       " 59     tracks       GenreId        INTEGER            0\n",
       " 60     tracks      Composer  NVARCHAR(220)            0\n",
       " 61     tracks  Milliseconds        INTEGER            0\n",
       " 62     tracks         Bytes        INTEGER            0\n",
       " 63     tracks     UnitPrice  NUMERIC(10,2)            0\n",
       " \n",
       " [64 rows x 4 columns])"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import sqlite3\n",
    "import pandas as pd\n",
    "\n",
    "# Connect to the database\n",
    "db_path = \"data/chinook.db\"\n",
    "conn = sqlite3.connect(db_path)\n",
    "\n",
    "# --- Tables ---\n",
    "tables = pd.read_sql_query(\"\"\"\n",
    "SELECT name FROM sqlite_master\n",
    "WHERE type='table' AND name NOT LIKE 'sqlite_%'\n",
    "ORDER BY name;\n",
    "\"\"\", conn)\n",
    "\n",
    "# --- Columns ---\n",
    "columns = pd.read_sql_query(\"\"\"\n",
    "SELECT\n",
    "    m.name AS table_name,\n",
    "    p.name AS column_name,\n",
    "    p.type AS data_type,\n",
    "    p.pk AS primary_key\n",
    "FROM sqlite_master m\n",
    "JOIN pragma_table_info(m.name) p\n",
    "WHERE m.type = 'table'\n",
    "  AND m.name NOT LIKE 'sqlite_%'\n",
    "ORDER BY m.name, p.cid;\n",
    "\"\"\", conn)\n",
    "\n",
    "tables, columns"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1099e365",
   "metadata": {},
   "source": [
    "### Generate Schema Documents"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "416e1c70",
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "'samples'",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mKeyError\u001b[39m                                  Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[2]\u001b[39m\u001b[32m, line 4\u001b[39m\n\u001b[32m      1\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mgenerate_schema_documents\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m make_schema_documents\n\u001b[32m      3\u001b[39m \u001b[38;5;66;03m# Generate schema documents\u001b[39;00m\n\u001b[32m----> \u001b[39m\u001b[32m4\u001b[39m documents = \u001b[43mmake_schema_documents\u001b[49m\u001b[43m(\u001b[49m\u001b[43mconn\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m      5\u001b[39m \u001b[38;5;28mprint\u001b[39m(documents[\u001b[32m0\u001b[39m].text)\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\dsteinec\\Documents\\Jupyter_Notebooks\\nl_to_data\\generate_schema_documents.py:246\u001b[39m, in \u001b[36mmake_schema_documents\u001b[39m\u001b[34m(conn)\u001b[39m\n\u001b[32m    244\u001b[39m \u001b[38;5;66;03m# ---- Column documents ----\u001b[39;00m\n\u001b[32m    245\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m column \u001b[38;5;129;01min\u001b[39;00m columns:\n\u001b[32m--> \u001b[39m\u001b[32m246\u001b[39m     column_document = \u001b[43mmake_column_document\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcolumn\u001b[49m\u001b[43m=\u001b[49m\u001b[43mcolumn\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtable\u001b[49m\u001b[43m=\u001b[49m\u001b[43mtable\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    247\u001b[39m     documents.append(column_document)\n\u001b[32m    249\u001b[39m \u001b[38;5;66;03m# ---- Relationship documents ----\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\dsteinec\\Documents\\Jupyter_Notebooks\\nl_to_data\\generate_schema_documents.py:167\u001b[39m, in \u001b[36mmake_column_document\u001b[39m\u001b[34m(table, column)\u001b[39m\n\u001b[32m    165\u001b[39m is_default = column[\u001b[33m'\u001b[39m\u001b[33mdefault\u001b[39m\u001b[33m'\u001b[39m] \u001b[38;5;28;01mif\u001b[39;00m column[\u001b[33m'\u001b[39m\u001b[33mdefault\u001b[39m\u001b[33m'\u001b[39m] \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;28;01melse\u001b[39;00m \u001b[33m'\u001b[39m\u001b[33mNone\u001b[39m\u001b[33m'\u001b[39m\n\u001b[32m    166\u001b[39m sample_text = \u001b[33m\"\u001b[39m\u001b[33mNone\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m--> \u001b[39m\u001b[32m167\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[43mcolumn\u001b[49m\u001b[43m[\u001b[49m\u001b[33;43m'\u001b[39;49m\u001b[33;43msamples\u001b[39;49m\u001b[33;43m'\u001b[39;49m\u001b[43m]\u001b[49m:\n\u001b[32m    168\u001b[39m     sample_text = \u001b[33m\"\u001b[39m\u001b[33m, \u001b[39m\u001b[33m\"\u001b[39m.join([\u001b[38;5;28mstr\u001b[39m(s) \u001b[38;5;28;01mfor\u001b[39;00m s \u001b[38;5;129;01min\u001b[39;00m column[\u001b[33m'\u001b[39m\u001b[33msamples\u001b[39m\u001b[33m'\u001b[39m]])\n\u001b[32m    169\u001b[39m col_text = (\n\u001b[32m    170\u001b[39m     \u001b[33mf\u001b[39m\u001b[33m'\u001b[39m\u001b[33mColumn: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mtable\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m.\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mcolumn_name\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[33m'\u001b[39m\n\u001b[32m    171\u001b[39m     \u001b[33mf\u001b[39m\u001b[33m'\u001b[39m\u001b[33mData type: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mdata_type\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[33m'\u001b[39m\n\u001b[32m   (...)\u001b[39m\u001b[32m    175\u001b[39m     \u001b[33mf\u001b[39m\u001b[33m'\u001b[39m\u001b[33mSample values: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00msample_text\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[33m'\u001b[39m\n\u001b[32m    176\u001b[39m )\n",
      "\u001b[31mKeyError\u001b[39m: 'samples'"
     ]
    }
   ],
   "source": [
    "from generate_schema_documents import make_schema_documents\n",
    "\n",
    "# Generate schema documents\n",
    "documents = make_schema_documents(conn)\n",
    "print(documents[0].text)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fc3a40a5",
   "metadata": {},
   "source": [
    "### Embed Documents in a Vector Database"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "71afb8b1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "86\n"
     ]
    }
   ],
   "source": [
    "from embed_documents_into_vector_db import upsert_schema_docs_to_lancedb, SchemaDoc\n",
    "\n",
    "vector_db = upsert_schema_docs_to_lancedb(\n",
    "                db_dir=\"chinook_schema_docs\",\n",
    "                documents=documents)\n",
    "print(vector_db.count_rows())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "760930a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "results = vector_db.search(\"How is the customer table linked?\").limit(5).to_pydantic(SchemaDoc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "ddca122d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[SchemaDoc(id='table:customers', doc_type='table', table='customers', column='', ref_table='', ref_column='', text='Table: customers\\nPrimary key: CustomerId\\nColumns:\\n - CustomerId (INTEGER) [PK NOT NULL]\\n - FirstName (NVARCHAR(40)) [NOT NULL]\\n - LastName (NVARCHAR(20)) [NOT NULL]\\n - Company (NVARCHAR(80))\\n - Address (NVARCHAR(70))\\n - City (NVARCHAR(40))\\n - State (NVARCHAR(40))\\n - Country (NVARCHAR(40))\\n - PostalCode (NVARCHAR(10))\\n - Phone (NVARCHAR(24))\\n - Fax (NVARCHAR(24))\\n - Email (NVARCHAR(60)) [NOT NULL]\\n - SupportRepId (INTEGER)\\nRelationships (foreign keys):\\n - customers.SupportRepId → employees.EmployeeId', vector=FixedSizeList(dim=384)),\n",
       " SchemaDoc(id='table:invoices', doc_type='table', table='invoices', column='', ref_table='', ref_column='', text='Table: invoices\\nPrimary key: InvoiceId\\nColumns:\\n - InvoiceId (INTEGER) [PK NOT NULL]\\n - CustomerId (INTEGER) [NOT NULL]\\n - InvoiceDate (DATETIME) [NOT NULL]\\n - BillingAddress (NVARCHAR(70))\\n - BillingCity (NVARCHAR(40))\\n - BillingState (NVARCHAR(40))\\n - BillingCountry (NVARCHAR(40))\\n - BillingPostalCode (NVARCHAR(10))\\n - Total (NUMERIC(10,2)) [NOT NULL]\\nRelationships (foreign keys):\\n - invoices.CustomerId → customers.CustomerId', vector=FixedSizeList(dim=384)),\n",
       " SchemaDoc(id='column:customers.CustomerId', doc_type='column', table='customers', column='CustomerId', ref_table='', ref_column='', text='Column: customers.CustomerId\\nData type: INTEGER\\nNullable: no\\nPrimary key: yes\\nDefault: None\\n', vector=FixedSizeList(dim=384)),\n",
       " SchemaDoc(id='rel:invoices.CustomerId->customers.CustomerId', doc_type='relationship', table='invoices', column='CustomerId', ref_table='customers', ref_column='CustomerId', text='Relationship: invoices.CustomerIdreferences customers.CustomerId\\nJoin hint: JOIN customers ON invoices.CustomerId = customers.CustomerId\\nOn update: NO ACTION; On delete: NO ACTION', vector=FixedSizeList(dim=384)),\n",
       " SchemaDoc(id='rel:customers.SupportRepId->employees.EmployeeId', doc_type='relationship', table='customers', column='SupportRepId', ref_table='employees', ref_column='EmployeeId', text='Relationship: customers.SupportRepIdreferences employees.EmployeeId\\nJoin hint: JOIN employees ON customers.SupportRepId = employees.EmployeeId\\nOn update: NO ACTION; On delete: NO ACTION', vector=FixedSizeList(dim=384))]"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6ae2f871",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "01d966d1",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\dsteinec\\AppData\\Local\\anaconda3\\envs\\nl-to-data\\Lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mKeyboardInterrupt\u001b[39m                         Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[1]\u001b[39m\u001b[32m, line 5\u001b[39m\n\u001b[32m      2\u001b[39m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01msqlite3\u001b[39;00m\n\u001b[32m      4\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mgenerate_schema_documents\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m make_schema_documents\n\u001b[32m----> \u001b[39m\u001b[32m5\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01membed_documents_into_vector_db\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m upsert_schema_docs_to_lancedb, \\\n\u001b[32m      6\u001b[39m     get_relevant_documents \n\u001b[32m      7\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mcreate_sql_query\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m generate_sql_cpu, docs_to_context_string, \\\n\u001b[32m      8\u001b[39m     extract_table_descriptions\n\u001b[32m     11\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[34m__name__\u001b[39m == \u001b[33m\"\u001b[39m\u001b[33m__main__\u001b[39m\u001b[33m\"\u001b[39m:\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\dsteinec\\Documents\\Jupyter_Notebooks\\nl_to_data\\embed_documents_into_vector_db.py:16\u001b[39m\n\u001b[32m     13\u001b[39m lm = registry.get(\u001b[33m\"\u001b[39m\u001b[33msentence-transformers\u001b[39m\u001b[33m\"\u001b[39m).create(name=\u001b[33m\"\u001b[39m\u001b[33mall-MiniLM-L6-v2\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m     15\u001b[39m \u001b[38;5;66;03m# Schema is defined using the LanceModel base class\u001b[39;00m\n\u001b[32m---> \u001b[39m\u001b[32m16\u001b[39m \u001b[38;5;28;43;01mclass\u001b[39;49;00m\u001b[38;5;250;43m \u001b[39;49m\u001b[34;43;01mSchemaDocLanceModel\u001b[39;49;00m\u001b[43m(\u001b[49m\u001b[43mLanceModel\u001b[49m\u001b[43m)\u001b[49m\u001b[43m:\u001b[49m\n\u001b[32m     17\u001b[39m \u001b[38;5;250;43m    \u001b[39;49m\u001b[33;43;03m'''Store schema document text and metadata, embed the text'''\u001b[39;49;00m\n\u001b[32m     18\u001b[39m \u001b[43m    \u001b[49m\u001b[38;5;28;43mid\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mstr\u001b[39;49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\dsteinec\\Documents\\Jupyter_Notebooks\\nl_to_data\\embed_documents_into_vector_db.py:25\u001b[39m, in \u001b[36mSchemaDocLanceModel\u001b[39m\u001b[34m()\u001b[39m\n\u001b[32m     23\u001b[39m ref_column: \u001b[38;5;28mstr\u001b[39m = \u001b[33m\"\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m     24\u001b[39m text: \u001b[38;5;28mstr\u001b[39m = lm.SourceField() \n\u001b[32m---> \u001b[39m\u001b[32m25\u001b[39m vector: Vector(\u001b[43mlm\u001b[49m\u001b[43m.\u001b[49m\u001b[43mndims\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m) = lm.VectorField()\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\dsteinec\\AppData\\Local\\anaconda3\\envs\\nl-to-data\\Lib\\site-packages\\lancedb\\embeddings\\sentence_transformers.py:54\u001b[39m, in \u001b[36mSentenceTransformerEmbeddings.ndims\u001b[39m\u001b[34m(self)\u001b[39m\n\u001b[32m     52\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mndims\u001b[39m(\u001b[38;5;28mself\u001b[39m):\n\u001b[32m     53\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m._ndims \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[32m---> \u001b[39m\u001b[32m54\u001b[39m         \u001b[38;5;28mself\u001b[39m._ndims = \u001b[38;5;28mlen\u001b[39m(\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mgenerate_embeddings\u001b[49m\u001b[43m(\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mfoo\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m)\u001b[49m[\u001b[32m0\u001b[39m])\n\u001b[32m     55\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m._ndims\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\dsteinec\\AppData\\Local\\anaconda3\\envs\\nl-to-data\\Lib\\site-packages\\lancedb\\embeddings\\sentence_transformers.py:68\u001b[39m, in \u001b[36mSentenceTransformerEmbeddings.generate_embeddings\u001b[39m\u001b[34m(self, texts)\u001b[39m\n\u001b[32m     57\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mgenerate_embeddings\u001b[39m(\n\u001b[32m     58\u001b[39m     \u001b[38;5;28mself\u001b[39m, texts: Union[List[\u001b[38;5;28mstr\u001b[39m], np.ndarray]\n\u001b[32m     59\u001b[39m ) -> List[np.array]:\n\u001b[32m     60\u001b[39m \u001b[38;5;250m    \u001b[39m\u001b[33;03m\"\"\"\u001b[39;00m\n\u001b[32m     61\u001b[39m \u001b[33;03m    Get the embeddings for the given texts\u001b[39;00m\n\u001b[32m     62\u001b[39m \n\u001b[32m   (...)\u001b[39m\u001b[32m     66\u001b[39m \u001b[33;03m        The texts to embed\u001b[39;00m\n\u001b[32m     67\u001b[39m \u001b[33;03m    \"\"\"\u001b[39;00m\n\u001b[32m---> \u001b[39m\u001b[32m68\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43membedding_model\u001b[49m.encode(\n\u001b[32m     69\u001b[39m         \u001b[38;5;28mlist\u001b[39m(texts),\n\u001b[32m     70\u001b[39m         convert_to_numpy=\u001b[38;5;28;01mTrue\u001b[39;00m,\n\u001b[32m     71\u001b[39m         normalize_embeddings=\u001b[38;5;28mself\u001b[39m.normalize,\n\u001b[32m     72\u001b[39m     ).tolist()\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\dsteinec\\AppData\\Local\\anaconda3\\envs\\nl-to-data\\Lib\\site-packages\\lancedb\\embeddings\\sentence_transformers.py:50\u001b[39m, in \u001b[36mSentenceTransformerEmbeddings.embedding_model\u001b[39m\u001b[34m(self)\u001b[39m\n\u001b[32m     43\u001b[39m \u001b[38;5;129m@property\u001b[39m\n\u001b[32m     44\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34membedding_model\u001b[39m(\u001b[38;5;28mself\u001b[39m):\n\u001b[32m     45\u001b[39m \u001b[38;5;250m    \u001b[39m\u001b[33;03m\"\"\"\u001b[39;00m\n\u001b[32m     46\u001b[39m \u001b[33;03m    Get the sentence-transformers embedding model specified by the\u001b[39;00m\n\u001b[32m     47\u001b[39m \u001b[33;03m    name, device, and trust_remote_code. This is cached so that the\u001b[39;00m\n\u001b[32m     48\u001b[39m \u001b[33;03m    model is only loaded once per process.\u001b[39;00m\n\u001b[32m     49\u001b[39m \u001b[33;03m    \"\"\"\u001b[39;00m\n\u001b[32m---> \u001b[39m\u001b[32m50\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mget_embedding_model\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\dsteinec\\AppData\\Local\\anaconda3\\envs\\nl-to-data\\Lib\\site-packages\\lancedb\\embeddings\\utils.py:248\u001b[39m, in \u001b[36mweak_lru.<locals>.wrapper.<locals>.inner\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m    246\u001b[39m \u001b[38;5;129m@functools\u001b[39m.wraps(func)\n\u001b[32m    247\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34minner\u001b[39m(\u001b[38;5;28mself\u001b[39m, *args, **kwargs):\n\u001b[32m--> \u001b[39m\u001b[32m248\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_func\u001b[49m\u001b[43m(\u001b[49m\u001b[43mweakref\u001b[49m\u001b[43m.\u001b[49m\u001b[43mref\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\dsteinec\\AppData\\Local\\anaconda3\\envs\\nl-to-data\\Lib\\site-packages\\lancedb\\embeddings\\utils.py:244\u001b[39m, in \u001b[36mweak_lru.<locals>.wrapper.<locals>._func\u001b[39m\u001b[34m(_self, *args, **kwargs)\u001b[39m\n\u001b[32m    242\u001b[39m \u001b[38;5;129m@functools\u001b[39m.lru_cache(maxsize)\n\u001b[32m    243\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34m_func\u001b[39m(_self, *args, **kwargs):\n\u001b[32m--> \u001b[39m\u001b[32m244\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[43m_self\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\dsteinec\\AppData\\Local\\anaconda3\\envs\\nl-to-data\\Lib\\site-packages\\lancedb\\embeddings\\sentence_transformers.py:83\u001b[39m, in \u001b[36mSentenceTransformerEmbeddings.get_embedding_model\u001b[39m\u001b[34m(self)\u001b[39m\n\u001b[32m     74\u001b[39m \u001b[38;5;129m@weak_lru\u001b[39m(maxsize=\u001b[32m1\u001b[39m)\n\u001b[32m     75\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mget_embedding_model\u001b[39m(\u001b[38;5;28mself\u001b[39m):\n\u001b[32m     76\u001b[39m \u001b[38;5;250m    \u001b[39m\u001b[33;03m\"\"\"\u001b[39;00m\n\u001b[32m     77\u001b[39m \u001b[33;03m    Get the sentence-transformers embedding model specified by the\u001b[39;00m\n\u001b[32m     78\u001b[39m \u001b[33;03m    name, device, and trust_remote_code. This is cached so that the\u001b[39;00m\n\u001b[32m   (...)\u001b[39m\u001b[32m     81\u001b[39m \u001b[33;03m    TODO: use lru_cache instead with a reasonable/configurable maxsize\u001b[39;00m\n\u001b[32m     82\u001b[39m \u001b[33;03m    \"\"\"\u001b[39;00m\n\u001b[32m---> \u001b[39m\u001b[32m83\u001b[39m     sentence_transformers = \u001b[43mattempt_import_or_raise\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m     84\u001b[39m \u001b[43m        \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43msentence_transformers\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43msentence-transformers\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\n\u001b[32m     85\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     86\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m sentence_transformers.SentenceTransformer(\n\u001b[32m     87\u001b[39m         \u001b[38;5;28mself\u001b[39m.name, device=\u001b[38;5;28mself\u001b[39m.device, trust_remote_code=\u001b[38;5;28mself\u001b[39m.trust_remote_code\n\u001b[32m     88\u001b[39m     )\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\dsteinec\\AppData\\Local\\anaconda3\\envs\\nl-to-data\\Lib\\site-packages\\lancedb\\util.py:155\u001b[39m, in \u001b[36mattempt_import_or_raise\u001b[39m\u001b[34m(module, mitigation)\u001b[39m\n\u001b[32m    142\u001b[39m \u001b[38;5;250m\u001b[39m\u001b[33;03m\"\"\"\u001b[39;00m\n\u001b[32m    143\u001b[39m \u001b[33;03mImport the specified module. If the module is not installed,\u001b[39;00m\n\u001b[32m    144\u001b[39m \u001b[33;03mraise an ImportError with a helpful message.\u001b[39;00m\n\u001b[32m   (...)\u001b[39m\u001b[32m    152\u001b[39m \u001b[33;03m    If not provided then the module name will be used.\u001b[39;00m\n\u001b[32m    153\u001b[39m \u001b[33;03m\"\"\"\u001b[39;00m\n\u001b[32m    154\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m155\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mimportlib\u001b[49m\u001b[43m.\u001b[49m\u001b[43mimport_module\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodule\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    156\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mImportError\u001b[39;00m:\n\u001b[32m    157\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mImportError\u001b[39;00m(\u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mPlease install \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mmitigation\u001b[38;5;250m \u001b[39m\u001b[38;5;129;01mor\u001b[39;00m\u001b[38;5;250m \u001b[39mmodule\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m\"\u001b[39m)\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\dsteinec\\AppData\\Local\\anaconda3\\envs\\nl-to-data\\Lib\\importlib\\__init__.py:126\u001b[39m, in \u001b[36mimport_module\u001b[39m\u001b[34m(name, package)\u001b[39m\n\u001b[32m    124\u001b[39m             \u001b[38;5;28;01mbreak\u001b[39;00m\n\u001b[32m    125\u001b[39m         level += \u001b[32m1\u001b[39m\n\u001b[32m--> \u001b[39m\u001b[32m126\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_bootstrap\u001b[49m\u001b[43m.\u001b[49m\u001b[43m_gcd_import\u001b[49m\u001b[43m(\u001b[49m\u001b[43mname\u001b[49m\u001b[43m[\u001b[49m\u001b[43mlevel\u001b[49m\u001b[43m:\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mpackage\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlevel\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\dsteinec\\AppData\\Local\\anaconda3\\envs\\nl-to-data\\Lib\\site-packages\\sentence_transformers\\__init__.py:10\u001b[39m\n\u001b[32m      7\u001b[39m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mos\u001b[39;00m\n\u001b[32m      8\u001b[39m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mwarnings\u001b[39;00m\n\u001b[32m---> \u001b[39m\u001b[32m10\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01msentence_transformers\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mbackend\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m (\n\u001b[32m     11\u001b[39m     export_dynamic_quantized_onnx_model,\n\u001b[32m     12\u001b[39m     export_optimized_onnx_model,\n\u001b[32m     13\u001b[39m     export_static_quantized_openvino_model,\n\u001b[32m     14\u001b[39m )\n\u001b[32m     15\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01msentence_transformers\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mcross_encoder\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m (\n\u001b[32m     16\u001b[39m     CrossEncoder,\n\u001b[32m     17\u001b[39m     CrossEncoderModelCardData,\n\u001b[32m     18\u001b[39m     CrossEncoderTrainer,\n\u001b[32m     19\u001b[39m     CrossEncoderTrainingArguments,\n\u001b[32m     20\u001b[39m )\n\u001b[32m     21\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01msentence_transformers\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mdatasets\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m ParallelSentencesDataset, SentencesDataset\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\dsteinec\\AppData\\Local\\anaconda3\\envs\\nl-to-data\\Lib\\site-packages\\sentence_transformers\\backend\\__init__.py:3\u001b[39m\n\u001b[32m      1\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01m__future__\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m annotations\n\u001b[32m----> \u001b[39m\u001b[32m3\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01m.\u001b[39;00m\u001b[34;01mload\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m load_onnx_model, load_openvino_model\n\u001b[32m      4\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01m.\u001b[39;00m\u001b[34;01moptimize\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m export_optimized_onnx_model\n\u001b[32m      5\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01m.\u001b[39;00m\u001b[34;01mquantize\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m export_dynamic_quantized_onnx_model, export_static_quantized_openvino_model\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\dsteinec\\AppData\\Local\\anaconda3\\envs\\nl-to-data\\Lib\\site-packages\\sentence_transformers\\backend\\load.py:7\u001b[39m\n\u001b[32m      4\u001b[39m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mlogging\u001b[39;00m\n\u001b[32m      5\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mpathlib\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m Path\n\u001b[32m----> \u001b[39m\u001b[32m7\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mtransformers\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mconfiguration_utils\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m PretrainedConfig\n\u001b[32m      9\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01msentence_transformers\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mbackend\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mutils\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m _save_pretrained_wrapper, backend_should_export, backend_warn_to_save\n\u001b[32m     11\u001b[39m logger = logging.getLogger(\u001b[34m__name__\u001b[39m)\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\dsteinec\\AppData\\Local\\anaconda3\\envs\\nl-to-data\\Lib\\site-packages\\transformers\\__init__.py:958\u001b[39m\n\u001b[32m    954\u001b[39m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01msys\u001b[39;00m\n\u001b[32m    956\u001b[39m _import_structure = {k: \u001b[38;5;28mset\u001b[39m(v) \u001b[38;5;28;01mfor\u001b[39;00m k, v \u001b[38;5;129;01min\u001b[39;00m _import_structure.items()}\n\u001b[32m--> \u001b[39m\u001b[32m958\u001b[39m import_structure = \u001b[43mdefine_import_structure\u001b[49m\u001b[43m(\u001b[49m\u001b[43mPath\u001b[49m\u001b[43m(\u001b[49m\u001b[34;43m__file__\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m.\u001b[49m\u001b[43mparent\u001b[49m\u001b[43m \u001b[49m\u001b[43m/\u001b[49m\u001b[43m \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mmodels\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mprefix\u001b[49m\u001b[43m=\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mmodels\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[32m    959\u001b[39m import_structure[\u001b[38;5;28mfrozenset\u001b[39m({})].update(_import_structure)\n\u001b[32m    961\u001b[39m sys.modules[\u001b[34m__name__\u001b[39m] = _LazyModule(\n\u001b[32m    962\u001b[39m     \u001b[34m__name__\u001b[39m,\n\u001b[32m    963\u001b[39m     \u001b[38;5;28mglobals\u001b[39m()[\u001b[33m\"\u001b[39m\u001b[33m__file__\u001b[39m\u001b[33m\"\u001b[39m],\n\u001b[32m   (...)\u001b[39m\u001b[32m    966\u001b[39m     extra_objects={\u001b[33m\"\u001b[39m\u001b[33m__version__\u001b[39m\u001b[33m\"\u001b[39m: __version__},\n\u001b[32m    967\u001b[39m )\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\dsteinec\\AppData\\Local\\anaconda3\\envs\\nl-to-data\\Lib\\site-packages\\transformers\\utils\\import_utils.py:2867\u001b[39m, in \u001b[36mdefine_import_structure\u001b[39m\u001b[34m(module_path, prefix)\u001b[39m\n\u001b[32m   2843\u001b[39m \u001b[38;5;129m@lru_cache\u001b[39m\n\u001b[32m   2844\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mdefine_import_structure\u001b[39m(module_path: \u001b[38;5;28mstr\u001b[39m, prefix: Optional[\u001b[38;5;28mstr\u001b[39m] = \u001b[38;5;28;01mNone\u001b[39;00m) -> IMPORT_STRUCTURE_T:\n\u001b[32m   2845\u001b[39m \u001b[38;5;250m    \u001b[39m\u001b[33;03m\"\"\"\u001b[39;00m\n\u001b[32m   2846\u001b[39m \u001b[33;03m    This method takes a module_path as input and creates an import structure digestible by a _LazyModule.\u001b[39;00m\n\u001b[32m   2847\u001b[39m \n\u001b[32m   (...)\u001b[39m\u001b[32m   2865\u001b[39m \u001b[33;03m    If `prefix` is not None, it will add that prefix to all keys in the returned dict.\u001b[39;00m\n\u001b[32m   2866\u001b[39m \u001b[33;03m    \"\"\"\u001b[39;00m\n\u001b[32m-> \u001b[39m\u001b[32m2867\u001b[39m     import_structure = \u001b[43mcreate_import_structure_from_path\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodule_path\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   2868\u001b[39m     spread_dict = spread_import_structure(import_structure)\n\u001b[32m   2870\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m prefix \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\dsteinec\\AppData\\Local\\anaconda3\\envs\\nl-to-data\\Lib\\site-packages\\transformers\\utils\\import_utils.py:2580\u001b[39m, in \u001b[36mcreate_import_structure_from_path\u001b[39m\u001b[34m(module_path)\u001b[39m\n\u001b[32m   2578\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m f \u001b[38;5;129;01min\u001b[39;00m os.listdir(module_path):\n\u001b[32m   2579\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m f != \u001b[33m\"\u001b[39m\u001b[33m__pycache__\u001b[39m\u001b[33m\"\u001b[39m \u001b[38;5;129;01mand\u001b[39;00m os.path.isdir(os.path.join(module_path, f)):\n\u001b[32m-> \u001b[39m\u001b[32m2580\u001b[39m         import_structure[f] = \u001b[43mcreate_import_structure_from_path\u001b[49m\u001b[43m(\u001b[49m\u001b[43mos\u001b[49m\u001b[43m.\u001b[49m\u001b[43mpath\u001b[49m\u001b[43m.\u001b[49m\u001b[43mjoin\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodule_path\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mf\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   2582\u001b[39m     \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m os.path.isdir(os.path.join(directory, f)):\n\u001b[32m   2583\u001b[39m         adjacent_modules.append(f)\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\dsteinec\\AppData\\Local\\anaconda3\\envs\\nl-to-data\\Lib\\site-packages\\transformers\\utils\\import_utils.py:2604\u001b[39m, in \u001b[36mcreate_import_structure_from_path\u001b[39m\u001b[34m(module_path)\u001b[39m\n\u001b[32m   2601\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m module_name.endswith(\u001b[33m\"\u001b[39m\u001b[33m.py\u001b[39m\u001b[33m\"\u001b[39m):\n\u001b[32m   2602\u001b[39m     \u001b[38;5;28;01mcontinue\u001b[39;00m\n\u001b[32m-> \u001b[39m\u001b[32m2604\u001b[39m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mopen\u001b[39m(os.path.join(directory, module_name), encoding=\u001b[33m\"\u001b[39m\u001b[33mutf-8\u001b[39m\u001b[33m\"\u001b[39m) \u001b[38;5;28;01mas\u001b[39;00m f:\n\u001b[32m   2605\u001b[39m     file_content = f.read()\n\u001b[32m   2607\u001b[39m \u001b[38;5;66;03m# Remove the .py suffix\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m<frozen codecs>:309\u001b[39m, in \u001b[36m__init__\u001b[39m\u001b[34m(self, errors)\u001b[39m\n",
      "\u001b[31mKeyboardInterrupt\u001b[39m: "
     ]
    }
   ],
   "source": [
    "from ctransformers import AutoModelForCausalLM\n",
    "import sqlite3\n",
    "\n",
    "from generate_schema_documents import make_schema_documents\n",
    "from embed_documents_into_vector_db import upsert_schema_docs_to_lancedb, \\\n",
    "    get_relevant_documents \n",
    "from create_sql_query import generate_sql_cpu, docs_to_context_string, \\\n",
    "    extract_table_descriptions\n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    query = \"What is the first song by the first artist?\"\n",
    "\n",
    "    # --- Connect to the database\n",
    "    db_path = \"data/chinook.db\"\n",
    "    conn = sqlite3.connect(db_path)\n",
    "\n",
    "    # --- Take SQL tables and columns, then generate \"documents\" for each\n",
    "    # NOTE: Later add LLM-generated descriptions for each table/column\n",
    "    documents = make_schema_documents(conn)\n",
    "    print(f'---Example Document---\\n{documents[0].text}\\n')\n",
    "\n",
    "    # --- Embed documents in a vector database NOTE: max(<thresh, 5)\n",
    "    vector_db = upsert_schema_docs_to_lancedb(\n",
    "                    db_dir=\"chinook_schema_docs\",\n",
    "                    documents=documents)\n",
    "    print(f'{vector_db.count_rows()} documents in vector database')\n",
    "\n",
    "    # --- Validate document relevance\n",
    "    # NOTE: Later, use another model to validate that documents match the query\n",
    "    \n",
    "    # --- Retrieve relevant columns from vector database\n",
    "    sql_context_df = get_relevant_documents(vector_db, query)\n",
    "    print(f'{len(sql_context_df)} relevant documents found for \"{query}\"')\n",
    "    table_descriptions = extract_table_descriptions(sql_context_df, documents)\n",
    "    sql_context = docs_to_context_string(sql_context_df)\n",
    "    sql_context += f'\\n{table_descriptions}'\n",
    "    \n",
    "    # --- Generate SQL query\n",
    "    model = AutoModelForCausalLM.from_pretrained(\n",
    "        \"MaziyarPanahi/sqlcoder-7b-2-GGUF\",\n",
    "        model_file=\"sqlcoder-7b-2.Q4_K_M.gguf\", \n",
    "        model_type=\"mistral\", \n",
    "        gpu_layers=0,  \n",
    "        context_length=4096,\n",
    "    )\n",
    "    sql_query = generate_sql_cpu(\n",
    "        question=\"Who are the top 3 artists?\", \n",
    "        retrieved_docs=sql_context, model=model)\n",
    "    print(sql_query)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "777ed226",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[DOCUMENT_START]\n",
      "Table: albums\n",
      "Primary key: AlbumId\n",
      "Columns:\n",
      " - AlbumId (INTEGER) [PRIMARY KEY NOT NULL] (ex: 1, 4, 2)\n",
      " - Title (NVARCHAR(160)) [NOT NULL] (ex: For Those About To Rock We Salute You, Balls to the Wall, Restless and Wild)\n",
      " - ArtistId (INTEGER) [NOT NULL] (ex: 1, 2, 3)\n",
      "Foreign key(s):\n",
      " - albums.ArtistId → artists.ArtistId[DOCUMENT_END]\n",
      "\n",
      "[DOCUMENT_START]\n",
      "Column: albums.ArtistId\n",
      "Data type: INTEGER\n",
      "Nullable: no\n",
      "Primary key: no\n",
      "Default: None\n",
      "Sample values: 1, 2, 3\n",
      "[DOCUMENT_END]\n",
      "\n",
      "[DOCUMENT_START]\n",
      "Column: albums.Title\n",
      "Data type: NVARCHAR(160)\n",
      "Nullable: no\n",
      "Primary key: no\n",
      "Default: None\n",
      "Sample values: For Those About To Rock We Salute You, Balls to the Wall, Restless and Wild\n",
      "[DOCUMENT_END]\n",
      "\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(sql_context)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "89207940",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dimensions of XX^T: (500, 500)\n",
      "Dimensions of X^T X: (1000, 1000)\n",
      "\n",
      "Top 5 Eigenvalues from XX^T (Sample Space):\n",
      "[2867.41231015 2856.83225367 2794.27358665 2783.5793239  2762.78522812]\n",
      "\n",
      "Top 5 Eigenvalues from X^T X (Feature Space):\n",
      "[2867.41231015 2856.83225367 2794.27358665 2783.5793239  2762.78522812]\n",
      "\n",
      "Are the top 500 eigenvalues identical? True\n",
      "\n",
      "Proportion of Variance Explained by PC1 (XX^T): 0.005741\n",
      "Proportion of Variance Explained by PC1 (X^T X): 0.005741\n"
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "fb048a95",
   "metadata": {},
   "outputs": [
    {
     "ename": "DatabaseError",
     "evalue": "Execution failed on sql ' SELECT a.ArtistName FROM artists a ORDER BY a.ArtistName ASC NULLS LAST LIMIT 3': no such column: a.ArtistName",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mOperationalError\u001b[39m                          Traceback (most recent call last)",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\dsteinec\\AppData\\Local\\anaconda3\\envs\\nl-to-data\\Lib\\site-packages\\pandas\\io\\sql.py:2664\u001b[39m, in \u001b[36mSQLiteDatabase.execute\u001b[39m\u001b[34m(self, sql, params)\u001b[39m\n\u001b[32m   2663\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m-> \u001b[39m\u001b[32m2664\u001b[39m     \u001b[43mcur\u001b[49m\u001b[43m.\u001b[49m\u001b[43mexecute\u001b[49m\u001b[43m(\u001b[49m\u001b[43msql\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   2665\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m cur\n",
      "\u001b[31mOperationalError\u001b[39m: no such column: a.ArtistName",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001b[31mDatabaseError\u001b[39m                             Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[9]\u001b[39m\u001b[32m, line 3\u001b[39m\n\u001b[32m      1\u001b[39m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mpandas\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mas\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mpd\u001b[39;00m\n\u001b[32m----> \u001b[39m\u001b[32m3\u001b[39m \u001b[43mpd\u001b[49m\u001b[43m.\u001b[49m\u001b[43mread_sql_query\u001b[49m\u001b[43m(\u001b[49m\u001b[43msql_query\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mconn\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\dsteinec\\AppData\\Local\\anaconda3\\envs\\nl-to-data\\Lib\\site-packages\\pandas\\io\\sql.py:528\u001b[39m, in \u001b[36mread_sql_query\u001b[39m\u001b[34m(sql, con, index_col, coerce_float, params, parse_dates, chunksize, dtype, dtype_backend)\u001b[39m\n\u001b[32m    525\u001b[39m \u001b[38;5;28;01massert\u001b[39;00m dtype_backend \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m lib.no_default\n\u001b[32m    527\u001b[39m \u001b[38;5;28;01mwith\u001b[39;00m pandasSQL_builder(con) \u001b[38;5;28;01mas\u001b[39;00m pandas_sql:\n\u001b[32m--> \u001b[39m\u001b[32m528\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mpandas_sql\u001b[49m\u001b[43m.\u001b[49m\u001b[43mread_query\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    529\u001b[39m \u001b[43m        \u001b[49m\u001b[43msql\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    530\u001b[39m \u001b[43m        \u001b[49m\u001b[43mindex_col\u001b[49m\u001b[43m=\u001b[49m\u001b[43mindex_col\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    531\u001b[39m \u001b[43m        \u001b[49m\u001b[43mparams\u001b[49m\u001b[43m=\u001b[49m\u001b[43mparams\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    532\u001b[39m \u001b[43m        \u001b[49m\u001b[43mcoerce_float\u001b[49m\u001b[43m=\u001b[49m\u001b[43mcoerce_float\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    533\u001b[39m \u001b[43m        \u001b[49m\u001b[43mparse_dates\u001b[49m\u001b[43m=\u001b[49m\u001b[43mparse_dates\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    534\u001b[39m \u001b[43m        \u001b[49m\u001b[43mchunksize\u001b[49m\u001b[43m=\u001b[49m\u001b[43mchunksize\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    535\u001b[39m \u001b[43m        \u001b[49m\u001b[43mdtype\u001b[49m\u001b[43m=\u001b[49m\u001b[43mdtype\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    536\u001b[39m \u001b[43m        \u001b[49m\u001b[43mdtype_backend\u001b[49m\u001b[43m=\u001b[49m\u001b[43mdtype_backend\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    537\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\dsteinec\\AppData\\Local\\anaconda3\\envs\\nl-to-data\\Lib\\site-packages\\pandas\\io\\sql.py:2728\u001b[39m, in \u001b[36mSQLiteDatabase.read_query\u001b[39m\u001b[34m(self, sql, index_col, coerce_float, parse_dates, params, chunksize, dtype, dtype_backend)\u001b[39m\n\u001b[32m   2717\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mread_query\u001b[39m(\n\u001b[32m   2718\u001b[39m     \u001b[38;5;28mself\u001b[39m,\n\u001b[32m   2719\u001b[39m     sql,\n\u001b[32m   (...)\u001b[39m\u001b[32m   2726\u001b[39m     dtype_backend: DtypeBackend | Literal[\u001b[33m\"\u001b[39m\u001b[33mnumpy\u001b[39m\u001b[33m\"\u001b[39m] = \u001b[33m\"\u001b[39m\u001b[33mnumpy\u001b[39m\u001b[33m\"\u001b[39m,\n\u001b[32m   2727\u001b[39m ) -> DataFrame | Iterator[DataFrame]:\n\u001b[32m-> \u001b[39m\u001b[32m2728\u001b[39m     cursor = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mexecute\u001b[49m\u001b[43m(\u001b[49m\u001b[43msql\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mparams\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   2729\u001b[39m     columns = [col_desc[\u001b[32m0\u001b[39m] \u001b[38;5;28;01mfor\u001b[39;00m col_desc \u001b[38;5;129;01min\u001b[39;00m cursor.description]\n\u001b[32m   2731\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m chunksize \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\dsteinec\\AppData\\Local\\anaconda3\\envs\\nl-to-data\\Lib\\site-packages\\pandas\\io\\sql.py:2676\u001b[39m, in \u001b[36mSQLiteDatabase.execute\u001b[39m\u001b[34m(self, sql, params)\u001b[39m\n\u001b[32m   2673\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m ex \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01minner_exc\u001b[39;00m\n\u001b[32m   2675\u001b[39m ex = DatabaseError(\u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mExecution failed on sql \u001b[39m\u001b[33m'\u001b[39m\u001b[38;5;132;01m{\u001b[39;00msql\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m'\u001b[39m\u001b[33m: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mexc\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m\"\u001b[39m)\n\u001b[32m-> \u001b[39m\u001b[32m2676\u001b[39m \u001b[38;5;28;01mraise\u001b[39;00m ex \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mexc\u001b[39;00m\n",
      "\u001b[31mDatabaseError\u001b[39m: Execution failed on sql ' SELECT a.ArtistName FROM artists a ORDER BY a.ArtistName ASC NULLS LAST LIMIT 3': no such column: a.ArtistName"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "pd.read_sql_query(sql_query, conn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1affa6b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "### Upload to GitHub\n",
    "### then add the table context to the top columns\n",
    "### then re-rank the top ones"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a7773113",
   "metadata": {},
   "outputs": [],
   "source": [
    "# NOTE: Try GPU version later"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1aa571d0",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9cd7d4ee",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "06ddc4c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "dd5a107d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "hi\n"
     ]
    }
   ],
   "source": [
    "print('hi')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "61a0e617",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "nl-to-data",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
